{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_str = '2023-08-01'\n",
    "# Define the URL of the ZIP file and the target directory\n",
    "url = f\"http://web.ais.dk/aisdata/aisdk-{date_str}.zip\"\n",
    "target_directory = \"../data\"\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# Define the path where the ZIP file will be saved\n",
    "zip_file_path = os.path.join(target_directory, \"aisdk-2023-08-01.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded successfully.\n",
      "Unzipped successfully.\n",
      "Cleaned up the ZIP file.\n"
     ]
    }
   ],
   "source": [
    "# Download the ZIP file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the download was successful\n",
    "if response.status_code == 200:\n",
    "    with open(zip_file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Downloaded successfully {url}.\")\n",
    "else:\n",
    "    print(f\"Failed to download {url}. Status code: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# Unzip the downloaded file\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(target_directory)\n",
    "    print(f\"Unzipped successfully {zip_file_path}.\")\n",
    "\n",
    "# Clean up: Remove the downloaded ZIP file\n",
    "os.remove(zip_file_path)\n",
    "print(f\"Cleaned up the ZIP file {zip_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = os.path.join(target_directory, f\"aisdk-{date_str}.csv\")\n",
    "# Use subprocess to run the 'wc -l' command and capture the output\n",
    "wc_out = subprocess.run([\"wc\", \"-l\", csv_file_path], stdout=subprocess.PIPE, text=True, check=True)\n",
    "csv_line_count = int(wc_out.stdout.split()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/aisdk-2023-08-01.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11804940"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = ['# Timestamp', 'Type of mobile', 'MMSI', 'Latitude', 'Longitude', \\\n",
    "       'Navigational status', 'ROT', 'SOG', 'COG', 'Heading', 'IMO', \\\n",
    "       'Callsign', 'Name', 'Ship type', 'Cargo type', 'Width', 'Length',\\\n",
    "       'Type of position fixing device', 'Draught', 'Destination', 'ETA',\\\n",
    "       'Data source type', 'A', 'B', 'C', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{target_directory}/chunks{date_str}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [02:17,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 100000\n",
    "input_csv = csv_file_path\n",
    "csv_reader = pd.read_csv(input_csv, chunksize=chunk_size, iterator=True)\n",
    "for i, chunk in tqdm(enumerate(csv_reader)):\n",
    "    chunk.to_csv(f'{target_directory}/chunks{date_str}/chunk_{i}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files in the directory\n",
    "directory_path = f'{target_directory}/chunks{date_str}'\n",
    "chunk_file_names = os.listdir(directory_path)\n",
    "chunk_files = [os.path.join(directory_path, file_name) for file_name in chunk_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = 100000  # Number of lines to process at a time\n",
    "\n",
    "# Define columns for which you want to calculate the mean\n",
    "mean_columns = ['Latitude', 'Longitude', 'ROT', 'SOG', 'COG', 'Heading','Draught', 'Length', 'Width']\n",
    "\n",
    "# Define columns for which you want the majority value\n",
    "majority_columns = ['Type of mobile', 'Navigational status', 'IMO', 'Callsign', 'Name',\n",
    "                    'Ship type', 'Cargo type', 'Type of position fixing device', 'Destination',\n",
    "                    'ETA', 'Data source type', 'A', 'B', 'C', 'D']\n",
    "\n",
    "# Define aggregation functions\n",
    "agg_functions = {col: 'mean' for col in mean_columns}\n",
    "# For majority_columns, return the mode if it exists, otherwise return None\n",
    "for col in majority_columns:\n",
    "    agg_functions[col] = lambda x: x.mode().iloc[0] if not x.empty and not x.mode().empty else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{target_directory}/chunks{date_str}/chunk_0.csv')\n",
    "df['# Timestamp'] = pd.to_datetime(df['# Timestamp'])\n",
    "# Round the datetime values to the nearest minute\n",
    "df['# Timestamp'] = df['# Timestamp'].dt.round('min')\n",
    "\n",
    "# Group by MMSI and # Timestamp, and apply the aggregation functions\n",
    "aggregated_chunk = df.groupby(['MMSI', '# Timestamp']).agg(agg_functions).reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the function to aggregate\n",
    "def aggregate_chunk(file_path):\n",
    "    chunk = pd.read_csv(file_path)\n",
    "    # Define your aggregation logic here\n",
    "    # Example: Calculate mean for numeric columns and mode for categorical columns\n",
    "    mean_columns = ['Latitude', 'Longitude', 'ROT', 'SOG', 'COG', 'Heading','Draught', 'Length', 'Width']\n",
    "    majority_columns = ['Type of mobile', 'Navigational status', 'IMO', 'Callsign', 'Name',\n",
    "                        'Ship type', 'Cargo type', 'Type of position fixing device', 'Destination',\n",
    "                        'ETA', 'Data source type', 'A', 'B', 'C', 'D']\n",
    "\n",
    "    # Apply aggregation functions\n",
    "    agg_functions = {col: 'mean' for col in mean_columns}\n",
    "    for col in majority_columns:\n",
    "        agg_functions[col] = lambda x: x.mode().iloc[0] if not x.empty and not x.mode().empty else None\n",
    "\n",
    "    # Apply the aggregation to the chunk\n",
    "    aggregated_chunk = chunk.groupby(['MMSI', '# Timestamp']).agg(agg_functions).reset_index()\n",
    "\n",
    "    return aggregated_chunk\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of CSV chunk file paths\n",
    "    chunk_files = chunk_files\n",
    "\n",
    "    # Create a pool of worker processes\n",
    "    with Pool(processes=6) as pool:  # Adjust the number of processes as needed\n",
    "        # Map the aggregate_chunk function to process each chunk in parallel\n",
    "        result_dataframes = pool.map(aggregate_chunk, chunk_files)\n",
    "\n",
    "    # Combine the results from all chunks\n",
    "    final_result = pd.concat(result_dataframes)\n",
    "\n",
    "    # Save the final aggregated DataFrame to a CSV file\n",
    "    final_result.to_csv(f\"{target_directory}/final_aggregated_data{date_str}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/aisdk-2023-08-01.csv', nrows=100000)\n",
    "df['# Timestamp'] = pd.to_datetime(df['# Timestamp'])\n",
    "        # Round the datetime values to the nearest minute\n",
    "df['# Timestamp'] = df['# Timestamp'].dt.round('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df.groupby(['MMSI', '# Timestamp']).agg(agg_functions).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.to_csv('../data/aisdk-2023-08-01_agg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-192340"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.shape[0]- csv_line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98452, 26)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dataframes[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
